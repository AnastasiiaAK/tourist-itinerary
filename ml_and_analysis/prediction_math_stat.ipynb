{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b28187",
   "metadata": {},
   "source": [
    "Здесь представлен код. Подробные выводы можно посмотреть в readme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de1d251",
   "metadata": {},
   "source": [
    "Полиномиальная регрессия (данные предобработаны)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[[\"stop_id\", \"next_stop\",\"stop_distance\", \"lon\", \"lng\"]], data[[\"timeBetweenStop\"]], test_size=0.33, random_state=42)\n",
    "\n",
    "# полиномиальная регресиия\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Fitting Polynomial Regression to the dataset \n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "\n",
    "poly = PolynomialFeatures(degree = 2) \n",
    "X_poly = poly.fit_transform(X_train[[\"stop_distance\", \"lon\", \"lng\"]]) \n",
    "\n",
    "poly.fit(X_poly, y_train) \n",
    "lin2 = LinearRegression().fit(X_poly, y_train) \n",
    "\n",
    "X_poly_test = poly.fit_transform(X_test[[\"stop_distance\", \"lon\", \"lng\"]]) \n",
    "\n",
    "\n",
    "y_pred = lin2.predict(X_poly_test)\n",
    "X_poly_validate = poly.fit_transform(validate[[\"stop_distance\", \"lon\", \"lng\"]])\n",
    "\n",
    "y_validate = lin2.predict(X_poly_validate)\n",
    "\n",
    "\n",
    "fill = pd.DataFrame(index=allStopWithTime.index[allStopWithTime.isnull().any(axis=1)], data= y_validate,columns=[\"timeBetweenStop\"])\n",
    "resultsData = allStopWithTime.fillna(fill)\n",
    "resultsData = resultsData[[\"stop_id\", \"next_stop\", \"timeBetweenStop\", \"hasStopThisInteval\"]]\n",
    "\n",
    "allBusWithTime = pd.merge(allBus, resultsData, how=\"left\" ,on=['stop_id', 'next_stop'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79216709",
   "metadata": {},
   "source": [
    "Нейронная сеть (данные предобработаны)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a040b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def reject_outliers(data, m=1):\n",
    "    return data[abs(data - np.mean(data)) < m * np.std(data)]\n",
    "\n",
    "if max(indexes) - min(indexes) > 5:\n",
    "    print(reject_outliers(indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orignal,X_test_orignal, y_train_orignal, y_test_orignal = X_train, X_test, y_train, y_test\n",
    "\n",
    "x_train0 = X_train[[\"lon\", \"lng\", \"stop_distance\"]]\n",
    "x_test0 = X_test[[\"lon\", \"lng\", \"stop_distance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a4121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x_train_torch = torch.tensor(x_train0.values)\n",
    "y_train_torch = torch.tensor(y_train.values)\n",
    "x_test_torch = torch.tensor(x_test0.values)\n",
    "y_test_torch = torch.tensor(y_test.values)\n",
    "\n",
    "x_train_torch.unsqueeze_(1)\n",
    "y_train_torch.unsqueeze_(1)\n",
    "x_test_torch.unsqueeze_(1)\n",
    "y_test_torch.unsqueeze_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(x_train0.values)\n",
    "X_test = torch.FloatTensor(x_test0.values)\n",
    "y_train = torch.LongTensor(y_train.values)\n",
    "y_test = torch.LongTensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70134a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "mBest = 10000\n",
    "\n",
    "class RegressionNet(torch.nn.Module):\n",
    "    random.seed(10)\n",
    "    def __init__(self, n_hidden_neurons):\n",
    "        super(RegressionNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(5, n_hidden_neurons)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        #self.fc2 = torch.nn.Linear(n_hidden_neurons, n_hidden_neurons)\n",
    "        #self.act2 = torch.nn.ReLU()\n",
    "        #self.fc3 = torch.nn.Linear(n_hidden_neurons, n_hidden_neurons)\n",
    "        #self.act3 = torch.nn.ReLu()\n",
    "        self.fc4 = torch.nn.Linear(n_hidden_neurons, n_hidden_neurons)\n",
    "        self.act4 = torch.nn.ReLU()\n",
    "        self.fc5 = torch.nn.Linear(n_hidden_neurons, n_hidden_neurons)\n",
    "        self.act5 = torch.nn.ReLU()\n",
    "        self.fc6 = torch.nn.Linear(n_hidden_neurons, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.fc1(x)\n",
    "      x = self.act1(x)\n",
    "      #x = self.fc2(x)\n",
    "      #x = self.act2(x)\n",
    "      #x = self.fc3(x)\n",
    "      #x = self.act3(x)\n",
    "      x = self.fc4(x) \n",
    "      x = self.act4(x)\n",
    "      x = self.fc5(x)\n",
    "      x = self.act5(x)\n",
    "      x = self.fc6(x)\n",
    "      return x\n",
    "\n",
    "\n",
    "    def inference(self, x):\n",
    "      x = self.forward(x)\n",
    "      x = self.sm(x)\n",
    "      return x\n",
    "\n",
    "net = RegressionNet(107)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "#optimizer = torch.optim.Adadelta(net.parameters(), lr=0.01, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "def loss(pred, target):\n",
    "    abses = abs(pred - target)\n",
    "    return abses.mean()\n",
    "'''\n",
    "#loss = torch.nn.CrossEntropyLoss()\n",
    "'''\n",
    "for epoch_index in range(5000):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_pred = net.forward(X_train)\n",
    "    loss_value = loss(y_pred, y_train)\n",
    "    loss_value.backward()\n",
    "    optimizer.step()\n",
    "    # make backward\n",
    "    # make step\n",
    "\n",
    "    if epoch_index % 100 == 0:\n",
    "      test_preds = net.forward(X_test)\n",
    "      #test_preds = test_preds.argmax(dim=1)\n",
    "      MSE = torch.sum((test_preds - y_test) ** 2, axis=0) / float(X_test.shape[0] - X_test.shape[1])\n",
    "\n",
    "      print(MSE) \n",
    "\n",
    "\n",
    "def metric(pred, target):\n",
    "    return (pred - target).abs().mean()\n",
    "\n",
    "print(metric(net.forward(X_test), y_test).item())\n",
    "\n",
    "'''\n",
    "def predict(net, x, y):\n",
    "    y_pred = net.forward(x)\n",
    "\n",
    "    plt.plot(x.numpy(), y.numpy(), 'o', label='Groud truth')\n",
    "    plt.plot(x.numpy(), y_pred.data.numpy(), 'o', c='r', label='Prediction');\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$y$')\n",
    "'''\n",
    "\n",
    "m = metric(net.forward(X_test), y_test).item()\n",
    "\n",
    "if m < mBest:\n",
    "    mBest = metric(net.forward(X_test), y_test).item()\n",
    "    iBest = i\n",
    "\n",
    "print(i, mBest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80bebf9",
   "metadata": {},
   "source": [
    "Посчитаем также рассчтояние до центра города ( как еще один параметр)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7925dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordsOfCenter = (59.93394044473929, 30.324399338624293)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f77b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy.distance\n",
    "from geopy import distance\n",
    "from geopy import Point\n",
    "p1 = Point(\"59.93394044473929 30.324399338624293\")\n",
    "data[\"distanceToCenter\"] = distance.distance(data[\"coordinates\"],p1).km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26002336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distancer(row):\n",
    "    coords_1 = (row['lon'], row['lng'])\n",
    "    coords_2 = (\"59.93394044473929, 30.324399338624293\")\n",
    "    return geopy.distance.VincentyDistance(coords_1, coords_2).km\n",
    "\n",
    "data['distanceToCenter'] = data.apply(distancer, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bef17e",
   "metadata": {},
   "source": [
    "также можно добавить бинарную переменную едет автобус в центр или из центра\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0352d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# также можно добавить бинарную переменную едет автобус в центр или из центра\n",
    "def distancerNext(row):\n",
    "    coords_1 = (row['lonNext'], row['lngNext'])\n",
    "    #print(pd.isna(row['lonNext']))\n",
    "    if pd.isna(row['lonNext']) != True:\n",
    "        coords_2 = (\"59.93394044473929, 30.324399338624293\")\n",
    "        return geopy.distance.VincentyDistance(coords_1, coords_2).km\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df0['distanceToCenterFromNext'] = df0.apply(distancerNext, axis=1)\n",
    "\n",
    "import numpy as np\n",
    "df0[\"inCenter\"] = np.where((df0.distanceToCenter > df0.distanceToCenterFromNext),1 , 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05708743",
   "metadata": {},
   "outputs": [],
   "source": [
    "Рассмотрим данные полученные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da390a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# гистограмма\n",
    "df0[[\"lon\", \"lng\", \"timeBetweenStop\",\"distanceToCenter\",\"lonNext\",\"lngNext\",  \"inCenter\" ]].hist();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459edba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# матрица рассеяния\n",
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(df0[[\"lon\", \"lng\", \"timeBetweenStop\",\"distanceToCenter\" ]], alpha=0.2, figsize=(6, 6), diagonal='kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f344e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# рассмотрим данные о времени движения в конкретный промежэуток времени для автобуса направленного в центр и из центраъ\n",
    "# с поомощью критерия Манна Уитни оценим является ли матенматическое ождидлание времени движения автобуса из центра и в центр одинаковым \n",
    "x = df0[df0['inCenter'] == 1]['timeBetweenStop']\n",
    "y = df0[df0['inCenter'] == 0]['timeBetweenStop']\n",
    "x.name, y.name = 'inCenter', 'fromCenter'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x[x < 600].hist(alpha=0.5, bins = 50)\n",
    "y[y < 600].hist(alpha=0.5, bins = 50)\n",
    "plt.axvline(x.mean(), color='red', alpha=0.8, linestyle='dashed')\n",
    "plt.axvline(y.mean(), color='blue', alpha=0.8, linestyle='dashed')\n",
    "plt.legend([x.name, y.name])\n",
    "plt.title(\"Test of equality of averages\")\n",
    "\n",
    "from scipy import stats\n",
    "res = stats.mannwhitneyu(x[x < 2000], y[y < 2000])\n",
    "print('p-value: {0}'.format(res[1]))\n",
    "# очень маленькое p-value. значит у нас есть основания отвергнуть гипотезу. Разница средних значений в выборках неслучайна\n",
    "# время для транпорта из центра и в центр отличаются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим тест Шапиро-Уилка для опроеджеллинения нормальности распредлений\n",
    "\n",
    "res = stats.shapiro(x)\n",
    "print('p-value: {0}'.format(res[1])) # распредление нормальное\n",
    "res = stats.shapiro(y)\n",
    "print('p-value: {0}'.format(res[1])) # распредление  нормальное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ea96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# рассмотрим такой жу тест но для данных автобьусов находящихся в радиусе 5 км от центра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86dcab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df0[df0['distanceToCenter'] < 5 ]['timeBetweenStop']\n",
    "y = df0[df0['distanceToCenter'] > 5 ]['timeBetweenStop']\n",
    "x.name, y.name = 'center', 'notCenter'\n",
    "\n",
    "x[x < 1000].hist(alpha=0.5, bins = 50)\n",
    "y[y < 1000].hist(alpha=0.5, bins = 50)\n",
    "plt.axvline(x.mean(), color='red', alpha=0.8, linestyle='dashed')\n",
    "plt.axvline(y.mean(), color='blue', alpha=0.8, linestyle='dashed')\n",
    "plt.legend([x.name, y.name])\n",
    "plt.title(\"Test of equality of averages\")\n",
    "\n",
    "from scipy import stats\n",
    "res = stats.mannwhitneyu(x, y)\n",
    "print('p-value: {0}'.format(res[1]))\n",
    "# очень маленькое p-value. значит у нас есть основания отвергнуть гипотезу. Разница средних значений в выборках неслучайна\n",
    "# время для транпорта из центра и в центр отличаются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47687b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# рассмотрим ращличия для севера и юга\n",
    "x = df0[(df0['lon'] < 59.93394044473929) & (df0['lng'] < 30.324399338624293)]['timeBetweenStop']\n",
    "y = df0[(df0['lon'] > 59.93394044473929) & (df0['lng'] > 30.324399338624293)]['timeBetweenStop']\n",
    "x.name, y.name = 'south', 'north'\n",
    "\n",
    "x.hist(alpha=0.5, bins = 50)\n",
    "y.hist(alpha=0.5, bins = 50)\n",
    "plt.axvline(x.mean(), color='red', alpha=0.8, linestyle='dashed')\n",
    "plt.axvline(y.mean(), color='blue', alpha=0.8, linestyle='dashed')\n",
    "plt.legend([x.name, y.name])\n",
    "plt.title(\"Test of equality of averages\")\n",
    "\n",
    "from scipy import stats\n",
    "res = stats.mannwhitneyu(x[x < 1000], y[y < 1000], alternative = \"greater\")\n",
    "print('p-value: {0}'.format(res[1]))\n",
    "\n",
    "# очень маленькое p-value. значит у нас есть основания отвергнуть гипотезу. Разница средних значений в выборках неслучайна\n",
    "# время для транпорта из центра и в центр отличаются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df[[\"lon\", \"lng\", \"timeBetweenStop\", \"distanceToCenter\", \"inCenter\",  \"stop_distance\"]]\n",
    "df0[\"speed\"] = df0[\"stop_distance\"] / df0[\"timeBetweenStop\"]\n",
    "\n",
    "df[df.timeBetweenStop < 400].boxplot(column = \"timeBetweenStop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем кластерны йаннализ по скорости движения транспората по городу\n",
    "df1.columns\n",
    "df1 = df0[[\"lon\", \"lng\", \"inCenter\", \"speed\"]]\n",
    "\n",
    "# Стандартизируем данные\n",
    "from sklearn import preprocessing\n",
    "norm = preprocessing.StandardScaler()\n",
    "norm.fit(df1)\n",
    "X = norm.transform(df1)\n",
    "#X = df0[df0.timeBetweenStop < 400].dropna().dropna()\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=5, random_state=42)\n",
    "model.fit(X)\n",
    "df1['cluster'] = model.labels_\n",
    "df1.groupby('cluster').mean()\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "K = range(1, 11)\n",
    "models = [KMeans(n_clusters=k, random_state=42).fit(X) for k in K]\n",
    "dist = [model.inertia_ for model in models]\n",
    "\n",
    "# Plot the elbow\n",
    "plt.plot(K, dist, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum of distances')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show() # по моему мнению оптимальные варинт 5 кластеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee60cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "link = linkage(X, 'ward', 'euclidean')\n",
    "dn = dendrogram(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11657b34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec2650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b3a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[[\"stop_distance\", \"lon\", \"lng\", \"distanceToCenter\", \"inCenter\"]], data[[\"timeBetweenStop\"]], test_size=0.33, random_state=42)\n",
    "data0 = data[[\"stop_distance\", \"lon\", \"lng\", \"distanceToCenter\", \"lonNext\", \"lngNext\", \"inCenter\", \"timeBetweenStop\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01695b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print('R^2: {0}'.format(model.score(X_train, y_train))) # результат на обучающей выборке\n",
    "\n",
    "coef = pd.DataFrame(zip(['intercept'] + X_train.columns.tolist(), [model.intercept_] + model.coef_.tolist()),\n",
    "                    columns=['predictor', 'coef'])\n",
    "model.coef_.tolist()\n",
    "\n",
    "\n",
    "# рассмотрим коэфииценты, по цоэффицентьам можно сказать как изменения независмой переменной влияет на зависимую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b23929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# матрица корреляций\n",
    "data0.corr()\n",
    "\n",
    "\n",
    "# коэффиценты регресии\n",
    "from scipy import stats\n",
    "\n",
    "def regression_coef(model, X, y):\n",
    "    a = model.coef_.tolist()[0]\n",
    "    a.insert(0, model.intercept_[0])\n",
    "    coef = pd.DataFrame(zip(['intercept'] + X_train.columns.tolist(), a),\n",
    "                    columns=['predictor', 'coef'])\n",
    "\n",
    "    X1 = np.append(np.ones((len(X),1)), X, axis=1)\n",
    "    b = np.append(model.intercept_, model.coef_)\n",
    "    MSE = np.sum((model.predict(X) - y) ** 2, axis=0) / float(X.shape[0] - X.shape[1])\n",
    "    var_b = MSE.timeBetweenStop * (np.linalg.inv(np.dot(X1.T, X1)).diagonal())\n",
    "    sd_b = np.sqrt(var_b)\n",
    "    t = b / sd_b\n",
    "    coef['pvalue'] = [2 * (1 - stats.t.cdf(np.abs(i), (len(X1) - 1))) for i in t]\n",
    "    return coef\n",
    "regression_coef(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a60d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# полиномиальная\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Fitting Polynomial Regression to the dataset \n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "\n",
    "X_train = X_train[[\"stop_distance\", \"lon\", \"lng\", \"distanceToCenter\", \"inCenter\"]]\n",
    "X_test = X_test[[\"stop_distance\", \"lon\", \"lng\", \"distanceToCenter\", \"inCenter\"]]\n",
    "\n",
    "poly = PolynomialFeatures(degree = 3) \n",
    "\n",
    "X_poly = poly.fit_transform(X_train) \n",
    "\n",
    "poly.fit(X_poly, y_train) \n",
    "\n",
    "lin2 = LinearRegression().fit(X_poly, y_train) \n",
    "\n",
    "X_poly_test = poly.fit_transform(X_test) \n",
    "\n",
    "\n",
    "y_pred = lin2.predict(X_poly_test)\n",
    "\n",
    "MSE = np.sum((y_pred - y_test) ** 2, axis=0) / float(X_test.shape[0] - X_test.shape[1])\n",
    "print(MSE)\n",
    "from sklearn.metrics import r2_score\n",
    "print('R^2: {0}'.format(r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da6cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# дерево решений \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor(random_state=42,\n",
    "                               # функция для impurity ('gini' или 'entropy')\n",
    "                               criterion='mse',\n",
    "                               # максимальная глубина дерева\n",
    "                               max_depth=3,\n",
    "                               # минимальное число элементов в узле для разбиения (может быть долей)\n",
    "                               min_samples_split=5,\n",
    "                               # минимальное число элементов в листе (может быть долей)\n",
    "                               min_samples_leaf=5,\n",
    "                               # минимальное значение дельты impurity\n",
    "                               # min_impurity_decrease=0,\n",
    "                               # веса для классов (можно дополнительно штрафовать за ошибку в нужных классах).\n",
    "                               # поддерживает опцию 'balanced'.\n",
    "                  \n",
    "                               # предварительная сортировка.\n",
    "                               # ускоряет обучение на данных небольшого размера или с ограниченной глубиной дерева.\n",
    "                               # иначе замедляет обучение.\n",
    "                               presort=False)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# рассмоотрим коэффициенты\n",
    "pd.DataFrame({'feature': X_train.columns,\n",
    "              'importance': model.feature_importances_}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11076a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# случайный лес\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(random_state=42,\n",
    "                              # опции, относящиеся к отдельным деревьям такаие же, как в tree.DecisionTreeClassifier\n",
    "                              # число деревьев в лесу\n",
    "                              n_estimators=6,\n",
    "                              # функция для impurity ('gini' или 'entropy')\n",
    "                              criterion='mse',\n",
    "                              max_depth=5,\n",
    "                              #min_samples_split = 2,\n",
    "                              #min_samples_leaf = 1\n",
    "                              )\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "MSE = np.sum((y_pred - y_test['timeBetweenStop'].tolist()) ** 2, axis=0) / float(X_test.shape[0] - X_test.shape[1])\n",
    "\n",
    "print(MSE)\n",
    "print('R^2: {0}'.format(r2_score(y_test, y_pred)))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "pd.DataFrame({'feature': X.columns,\n",
    "              'importance': model.feature_importances_}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb619276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# градиентный бустинг\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=42,\n",
    "                                  # Число деревьев, участвующих в приближении решения\n",
    "                                  n_estimators=32,\n",
    "                                  # Максимальная глубина каждого дерева\n",
    "                                  max_depth=3,\n",
    "                                  # Параметр, уменьшающий переобучение, являющемся весом отдельного дерева.\n",
    "                                  # Рекомендуется выставлять небольшие значения из (0, 0.3].\n",
    "                                  learning_rate=0.1\n",
    "                                  # Есть и другие параметры, уменьшающие размер дерева,\n",
    "                                  # такие же как у DecisionTreeClassifier\n",
    "                                  )\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "#print (classification_report(y_test, y_pred))\n",
    "# classification_report считает 3 метрики - точность, полноту и ф1\n",
    "MSE = np.sum((y_pred - y_test['timeBetweenStop'].tolist()) ** 2, axis=0) / float(X_test.shape[0] - X_test.shape[1])\n",
    "\n",
    "print(MSE)\n",
    "print('R^2: {0}'.format(r2_score(y_test, y_pred)))\n",
    "\n",
    "\n",
    "fi = pd.DataFrame({'features': X_train.columns, 'importance': model.feature_importances_})\n",
    "fi.sort_values('importance', ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08559cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost. Также подбираем параметры когда модель выдает лучшие результаты\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "iBest = 0\n",
    "jBest = 0\n",
    "kBest = 0\n",
    "mseBest = 10000\n",
    "for i in range (2, 600, 5):\n",
    "    for j in range (2, 30):\n",
    "        for k in [0.1]:\n",
    "            model = XGBRegressor(seed=42,\n",
    "                            n_estimators=i,\n",
    "                            max_depth=j,\n",
    "                            learning_rate=k)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "            MSE = np.sum((y_pred - y_test['timeBetweenStop'].tolist()) ** 2, axis=0) / float(X_test.shape[0] - X_test.shape[1])\n",
    "\n",
    "            if MSE < mseBest:\n",
    "                \n",
    "                mseBest = MSE\n",
    "                iBest = i\n",
    "                jBest = j\n",
    "                kBest = k\n",
    "\n",
    "print(mseBest)\n",
    "print('R^2: {0}'.format(r2_score(y_test, y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7012cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "'''\n",
    "X_train = df.drop('income', axis=1)\n",
    "y_train = df['income']\n",
    "\n",
    "X_test = test.drop('income', axis=1)\n",
    "y_test = test['income']\n",
    "\n",
    "cat_features = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "cat_features = [i for i, x in enumerate(df.columns) if x in cat_features]\n",
    "\n",
    "'''\n",
    "\n",
    "model = CatBoostRegressor(random_seed=42,\n",
    "                          iterations=112,\n",
    "                          depth=5,\n",
    "                          learning_rate=0.1,\n",
    "                          verbose=False)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "#print (classification_report(y_test, y_pred))\n",
    "MSE = np.sum((y_pred - y_test['timeBetweenStop'].tolist()) ** 2, axis=0) / float(X_test.shape[0] - X_test.shape[1])\n",
    "\n",
    "print('R^2: {0}'.format(r2_score(y_test, y_pred)))\n",
    "\n",
    "\n",
    "fi = pd.DataFrame({'features': X_train.columns, 'importance': model.feature_importances_})\n",
    "fi.sort_values('importance', ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
