{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"01_train.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df .rename(columns={\"y\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"01_test.csv\")\n",
    "test_df = test_df .rename(columns={\"y\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  65938, -109121,  101371,   68046,  499646,   51569, -170592,\n",
       "         -84944,  -74420,       3],\n",
       "       [  83426,  -28524, -100525,  244933, -219593,   54303, -206699,\n",
       "         146491,  -31888,      10],\n",
       "       [ -96851,   15578,   -5402,  289095,  -57329,   58332, -214913,\n",
       "        -138813,   34742,      12],\n",
       "       [  10072,  -26539,  186370,   72241, -112577,   64956, -228388,\n",
       "        -154687,  221456,      12],\n",
       "       [ -86930,  -66303,  527176,  224934,  -79165,   57980, -195603,\n",
       "        -186762,   11842,       1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train_df.values\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возвращает номер наибольшего класса, по колву принадлежащих ему элементов\n",
    "def classify_data(data): \n",
    "    \n",
    "    label_column = data[:, -1]#столбец значений\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True) #уолво значений каждого класса\n",
    "\n",
    "    index = counts_unique_classes.argmax() #индекс с самым большим колвом классов\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    return classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# составляем словарь,где каждому столбцу сопоставляем уникальные значения в нем находящиеся\n",
    "def get_potential_splits(data):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    for column_index in range(n_columns - 1):\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        potential_splits[column_index] = unique_values\n",
    "    \n",
    "    return potential_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделяем на две части меньше split_value и больше. определенную колонку\n",
    "def split_data(data, split_column, split_value):\n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    data_below = data[split_column_values <= split_value]\n",
    "    data_above = data[split_column_values >  split_value]\n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def calculate_entropy(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum() # вероятность, что принадлежит к определенному классу\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "     \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вероятность, что строка принадлежит к разделенному классу \n",
    "def calculate_overall_entropy(data_below, data_above):\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_entropy =  (p_data_below * calculate_entropy(data_below) \n",
    "                      + p_data_above * calculate_entropy(data_above))\n",
    "    \n",
    "    return overall_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(data, potential_splits):\n",
    "    \n",
    "    overall_entropy = 9999\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, counter=0, min_samples=2, max_depth=5):\n",
    "    \n",
    "    # data preparations\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df           \n",
    "    \n",
    "    \n",
    "    if (len(data) < min_samples) or (counter == max_depth):\n",
    "        classification = classify_data(data)\n",
    "        \n",
    "        return classification\n",
    "\n",
    "    else:    \n",
    "        counter += 1\n",
    "\n",
    "        # разделяем данные на две части\n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split(data, potential_splits)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        # определяем вопрос\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        question = \"{} <= {}\".format(feature_name, split_value)\n",
    "\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        # находим рекурсивно ответ\n",
    "        yes_answer = decision_tree_algorithm(data_below, counter, min_samples, max_depth)\n",
    "        no_answer = decision_tree_algorithm(data_above, counter, min_samples, max_depth)\n",
    "        \n",
    "        sub_tree[question].append(yes_answer)\n",
    "        sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x7 <= -214911': [{'x2 <= -155079': [{'x1 <= 40137': [16, 16]},\n",
      "                                      {'x4 <= 163941': [12, 12]}]},\n",
      "                   {'x3 <= 190305': [{'x1 <= 58572': [11, 10]},\n",
      "                                     {'x5 <= -217110': [17, 1]}]}]}\n"
     ]
    }
   ],
   "source": [
    "tree = decision_tree_algorithm(train_df, max_depth=3)\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "\n",
    "    if example[feature_name] <= float(value):\n",
    "        answer = tree[question][0]\n",
    "    else:\n",
    "        answer = tree[question][1]\n",
    "        \n",
    "        \n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = test_df.iloc[10]\n",
    "classify_example(example, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 12, 12, 12, 12, 12, 1, 11, 11, 12, 10, 1, 11, 1, 1, 11, 1, 17, 10, 17, 16, 11, 12, 11, 11, 1, 12, 1, 1, 12, 1, 12, 12, 12, 1, 12, 11, 12, 12, 10, 17, 1, 1, 1, 11, 12, 1, 17, 1, 11, 17, 1, 11, 12, 12, 16, 10, 1, 11, 12, 11, 10, 11, 1, 11, 11, 1, 1, 11, 11, 16, 1, 1, 1, 1, 11, 12, 12, 11, 12, 11, 12, 12, 1, 12, 11, 11, 11, 11, 1, 10, 16, 11, 12, 10, 11, 1, 11, 1, 11, 11, 11, 12, 10, 17, 10, 11, 11, 17, 11, 1, 11, 11, 12, 12, 12, 16, 12, 1, 12, 11, 12, 11, 1, 16, 11, 11, 12, 11, 12, 11, 1, 1, 11, 1, 11, 1, 1, 11, 12, 11, 1, 11, 11, 11, 1, 12, 12, 12, 1, 1, 11, 11, 11, 16, 12, 12, 1, 17, 11, 11, 10, 10, 12, 11, 11, 11, 11, 10, 11, 10, 12, 12, 1, 11, 12, 11, 16, 12, 16, 11, 17, 12, 12, 12, 12, 12, 12, 17, 11, 11, 12, 11, 12, 10, 1, 17, 12, 12, 12, 11, 11, 11, 11, 11, 11, 11, 12, 12, 11, 11, 12, 12, 11, 11, 11, 16, 12, 1, 10, 12, 11, 16, 16, 12, 12, 11, 12, 11, 12, 12, 1, 11, 11, 10, 1, 10, 11, 11, 1, 1, 11, 11, 11, 11, 10, 12, 1, 12, 10, 11, 1, 11, 11, 12, 12, 11, 11, 11, 11, 11, 11, 11, 11, 10, 1, 11, 11, 10, 11, 11, 1, 12, 11, 1, 12, 12, 11, 10, 17, 10, 16, 1, 11, 16, 16, 11, 10, 1, 1, 1, 11, 16, 12, 12, 12, 16, 10, 11, 12, 12, 11, 10, 1, 10, 1, 1, 10, 12, 1, 12, 11, 11, 1, 1, 11, 12, 11, 12, 11, 12, 16, 12, 12, 11, 11, 1, 11, 10, 11, 12, 12, 1, 12, 1, 16, 1, 11, 1, 11, 12, 12, 10, 1, 11, 11, 11, 10, 12, 1, 12, 16, 11, 11, 1, 12, 11, 12, 1, 12, 1, 11, 16, 1, 12, 12, 11, 16, 12, 11, 11, 11, 11, 11, 11, 1, 12, 12, 17, 11, 12, 1, 16, 11, 11, 17, 11, 11, 11, 11, 17, 1, 10, 11, 12, 12, 16, 12, 1, 11, 10, 1, 12, 12, 11, 16, 11, 11, 11, 12, 11, 10, 1, 12, 12, 1, 12, 1, 10, 10, 11, 11, 12, 11, 11, 11, 12, 10, 12, 17, 11, 1, 1, 11, 11, 11, 11, 11, 11, 11, 16, 11, 12, 12, 16, 10, 11, 11, 10, 17, 12, 16, 17, 12, 1, 10, 10, 10, 12, 10, 11, 11, 11, 16, 11, 11, 11, 11, 12, 11, 11, 11, 12, 10, 11, 1, 16, 12, 16, 11, 12, 11, 11, 10, 12, 1, 1, 11, 1, 12, 12, 17, 16, 1, 10, 12, 12, 1, 1, 12, 11, 16, 11, 1, 11, 11, 11, 1, 12, 11, 1, 12, 11, 11, 10, 12, 16, 12, 1, 17, 11, 11, 12, 1, 12, 11, 11, 12, 12, 12, 12, 12, 1, 1, 12, 12, 11, 17, 1, 1, 1, 11, 1, 11, 12, 11, 17, 12, 11, 11, 11, 10, 12, 1, 16, 1, 11, 12, 10, 1, 11, 11, 10, 12, 1, 11, 11, 11, 11, 12, 17, 12, 1, 16, 17, 12, 12, 11, 10, 16, 12, 12, 11, 11, 17, 11, 11, 17, 1, 1, 11, 12, 11, 11, 12, 10, 12, 12, 12, 10, 10, 16, 11, 1, 11, 1, 16, 11, 11, 11, 11, 11, 11, 1, 12, 12, 11, 12, 11, 12, 11, 12, 12, 1, 11, 11, 11, 11, 11, 10, 11, 17, 11, 11, 11, 11, 11, 11, 11, 1, 12, 12, 12, 11, 11, 11, 12, 12, 1, 1, 12, 11, 1, 1, 1, 10, 10, 11, 16, 12, 12, 11, 11, 11, 16, 1, 11, 11, 11, 11, 1, 12, 1, 10, 10, 10, 11, 11, 12, 10, 11, 10, 11, 11, 11, 11, 12, 1, 11, 11, 11, 11, 17, 10, 11, 17, 11, 11, 12, 11, 12, 11, 11, 12, 12, 10, 12, 17, 11, 1, 1, 12, 11, 11, 11, 12, 1, 1, 11, 12, 1, 12, 12, 12, 16, 11, 16, 12, 11, 11, 10, 12, 1, 10, 1, 11, 12, 10, 11, 11, 12, 12, 11, 11, 11, 11, 11, 11, 11, 1, 11, 11, 11, 11, 10, 1, 1, 11, 12, 12, 11, 12, 12, 12, 10, 12, 17, 11, 1, 12, 11, 1, 11, 11, 11, 11, 10, 11, 16, 1, 1, 12, 1, 1, 11, 11, 11, 12, 11, 1, 17, 16, 11, 10, 10, 12, 1, 11, 12, 11, 11, 12, 12, 11, 11, 11, 1, 1, 12, 11, 12, 1, 1, 12, 10, 1, 11, 1, 1, 16, 11, 11, 11, 10, 17, 11, 16, 10, 1, 1, 12, 11, 10, 12, 12, 11, 11, 17, 1, 11, 12, 16, 11, 11, 17, 10, 1, 12, 1, 10, 11, 12, 12, 11, 1, 11, 1, 1, 11, 10, 12, 1, 12, 12, 1, 11, 11, 1, 17, 10, 11, 10, 11, 10, 11, 12, 10, 11, 11, 11, 11, 1, 12, 11, 11, 12, 12, 11, 11, 1, 11, 16, 12, 11, 11, 12, 11, 11, 12, 11, 1, 1, 11, 12, 11, 11, 11, 11, 1, 12, 11, 11, 11, 11, 16, 11, 10, 11, 11, 12, 12, 11, 1, 17, 11, 11, 1, 12, 10, 12, 17, 11, 1, 12, 1, 11, 17, 12, 17, 17, 12, 11, 12, 11, 11, 12, 17, 12, 16, 11, 1, 1, 11, 11, 1, 10, 10, 11, 11, 11, 12, 10, 1, 1, 16, 1, 11, 11, 1, 11, 1, 12, 11, 11, 11, 11, 1, 1, 1, 1, 11, 12, 12, 1, 12, 12, 11, 11, 11, 11, 11, 1, 11, 16, 12, 12, 1, 10, 11, 1, 12, 11, 1, 12, 10, 12, 11, 1, 11, 12, 12, 12, 12, 11, 11, 17, 12, 1, 11, 1, 12, 17, 11, 1, 12, 1, 1, 1, 1, 17, 11, 17, 12, 12, 10, 12, 12, 12, 1, 11, 17, 11, 11, 11, 11, 1, 1, 11, 12, 1, 10, 11, 1, 11, 11, 11, 11, 11, 1, 12, 1, 12, 11, 12, 16, 11, 16, 11, 12, 11, 11, 1, 16, 1, 10, 12, 11, 11, 11, 11, 11, 11, 16, 11, 12, 1, 1, 11, 12, 1, 1, 10, 17, 11, 10, 1, 1, 12, 12, 16, 1, 12, 1, 10, 1, 17, 16, 12, 12, 12, 1, 12, 1, 11, 1, 10, 16, 17, 12, 11, 11, 1, 1, 1, 11, 10, 11, 11, 11, 12, 11, 11, 11, 1, 12, 11, 11, 12, 17, 16, 11, 1, 11, 17, 16, 10, 11, 11, 11, 12, 12, 11, 10, 11, 10, 11, 1, 17, 11, 16, 11, 11, 11, 11, 10, 16, 11, 1, 10, 12, 10, 1, 12, 10, 17, 1, 17, 11, 11, 11, 12, 11, 11, 10, 11, 11, 10, 11, 1, 11, 11, 12, 12, 12, 11, 11, 10, 11, 16, 11, 11, 11, 11, 1, 1, 11, 12, 11, 10, 11, 1, 1, 11, 10, 11, 11, 11, 12, 12, 1, 11, 11, 11, 1, 10, 11, 12, 11, 12, 11, 11, 11, 11, 1, 12, 12, 11, 11, 12, 17, 12, 11, 11, 1, 11, 10, 11, 1, 12, 1, 12, 11, 11, 16, 1, 11, 1, 16, 12, 12, 12, 11, 11, 1, 11, 11, 12, 12, 10, 11, 10, 12, 11, 12, 11, 1, 12, 12, 11, 17, 12, 11, 1, 1, 11, 11, 1, 11, 12, 1, 16, 11, 11, 1, 11, 11, 12, 11, 10, 12, 11, 1, 11, 1, 1, 12, 12, 10, 1, 11, 17, 11, 1, 12, 12, 10, 10, 11, 11, 1, 11, 16, 12, 12, 12, 1, 1, 11, 11, 11, 11, 17, 11, 12, 11, 11, 11, 12, 17, 1, 11, 11, 12, 17, 11, 16, 1, 11, 12, 12, 10, 11, 11, 10, 12, 10, 1, 11, 11, 12, 11, 11, 12, 11, 11, 1, 11, 10, 11, 17, 1, 16, 11, 10, 11, 17, 12, 1, 11, 11, 17, 11, 1, 10, 12, 12, 11, 12, 11, 17, 16, 1, 1, 11, 10, 12, 11, 16, 10, 12, 12, 16, 12, 17, 12, 11, 12, 1, 10, 12, 1, 10, 1, 1, 1, 17, 12, 11, 1, 11, 11, 11, 12, 11, 12, 12, 1, 17, 10, 11, 11, 12, 11, 12, 12, 12, 16, 11, 11, 1, 1, 11, 1, 11, 10, 10, 1, 1, 16, 12, 11, 11, 11, 11, 1, 10, 16, 12, 1, 16, 12, 11, 17, 1, 1, 16, 12, 12, 11, 12, 1, 11, 12, 1, 11, 10, 11, 12, 10, 11, 11, 11, 10, 12, 11, 11, 12, 11, 16, 10, 17, 1, 1, 12, 11, 1, 1, 11, 1, 11, 16, 16, 12, 12, 11, 11, 10, 11, 17, 11, 10, 12, 12, 11, 11, 1, 17, 12, 10, 11, 16, 12, 11, 10, 11, 1, 12, 11, 11, 16, 10, 11, 11, 1, 12, 12, 11, 1, 11, 17, 17, 11, 1, 11, 12, 1, 12, 11, 12, 1, 10, 11, 12, 1, 1, 11, 12, 1, 12, 12, 10, 10, 10, 16, 11, 16, 1, 11, 10, 11, 11, 12, 12, 11, 1, 11, 16, 11, 11, 11, 11, 12, 1, 12, 11, 12, 11, 11, 11, 11, 12, 11, 11, 10, 11, 11, 11, 12, 11, 11, 11, 11, 11, 12, 17, 12, 1, 12, 12, 11, 11, 12, 12, 11, 12, 12, 11, 12, 17, 10, 11, 11, 12, 10, 12, 16, 11, 16, 16, 16, 11, 1, 1, 11, 12, 1, 12, 11, 1, 17, 11, 11, 11, 1, 11, 11, 17, 11, 17, 1, 12, 1, 16, 11, 11, 12, 1, 11, 17, 11, 11, 1, 17, 10, 11, 1, 11, 11, 11, 12, 12, 12, 11, 17, 16, 11, 11, 11, 10, 1, 12, 1, 1, 11, 1, 11, 11, 11, 11, 11, 12, 11, 11, 1, 11, 10, 11, 1, 11, 1, 12, 11, 11, 12, 12, 11, 11, 1, 11, 12, 11, 11, 10, 10, 12, 10, 12, 12, 11, 11, 11, 11, 12, 1, 12, 12, 10, 11, 1, 11, 12, 10, 11, 11, 11, 1, 1, 11, 12, 11, 11, 11, 11, 1, 11, 11, 1, 11, 11, 11, 11, 12, 1, 1, 11, 1, 12, 11, 11, 11, 11, 11, 11, 11, 12, 1, 16, 1, 11, 16, 12, 11, 1, 16, 12, 11, 11, 11, 11, 17, 16, 12, 12, 16, 11, 1, 1, 1, 16, 1, 11, 12, 12, 1, 12, 11, 1, 1, 10, 1, 1, 12, 11, 12, 11, 11, 1, 11, 1, 1, 11, 11, 17, 12, 12, 11, 11, 12, 11, 11, 12, 12, 11, 1, 11, 11, 1, 11, 11, 1, 11, 12, 1, 11, 1, 12, 11, 1, 11, 10, 12, 12, 11, 1, 11, 12, 10, 12, 11, 12, 12, 10, 12, 11, 12, 11, 1, 12, 12, 11, 12, 1, 11, 1, 12, 11, 10, 10, 11, 11, 12, 1, 12, 1, 11, 1, 11, 11, 16, 11, 16, 11, 11, 1, 1, 1, 1, 12, 10, 12, 12, 11, 17, 17, 11, 12, 12, 12, 11, 10, 11, 12, 11, 12, 1, 12, 11, 12, 12, 10, 12, 11, 12, 12, 1, 16, 1, 11, 11, 1, 11, 11, 10, 12, 1, 1, 11, 11, 11, 11, 11, 11, 12, 10, 1, 1, 11, 12, 1, 11, 12, 12, 17, 11, 11, 11, 1, 11, 11, 12, 11, 1, 1, 12, 1, 1, 11, 12, 1, 10, 12, 12, 10, 11, 11, 1, 1, 10, 1, 12, 11, 12, 12, 11, 17, 12, 12, 12, 11, 1, 11, 11, 16, 11, 1, 1, 16, 1, 16, 10, 12, 16, 12, 1, 10, 11, 16, 1, 12, 1, 17, 11, 11, 12, 1, 16, 12, 11, 17, 1, 11, 11, 11, 12, 10, 12, 12, 1, 11, 12, 11, 11, 12, 1, 11, 16, 12, 11, 16, 11, 17, 1, 12, 16, 11, 11, 12, 12, 16, 1, 11, 10, 1, 11, 1, 1, 11, 11, 11, 11, 11, 10, 12, 11, 16, 12, 11, 11, 11, 17, 12, 12, 11, 1, 11, 12, 12, 16, 1, 12, 16, 11, 12, 11, 12, 10, 11, 16, 11, 12, 11, 11, 11, 11, 1, 11, 12, 11, 17, 11, 12, 12, 12, 1, 12, 12, 11, 11, 1, 12, 10, 12, 17, 1, 17, 1, 12, 1, 11, 1, 17, 11, 1, 11, 11, 12, 12, 11, 12, 11, 1, 12, 16, 12, 11, 11, 12, 12, 16, 11, 12, 10, 11, 11, 11, 12, 10, 12, 12, 11, 12, 11, 12, 10, 16, 10, 12, 11, 1, 11, 12, 16, 1, 12, 11, 11, 16, 12, 10, 12, 12, 17, 10, 12, 11, 11, 11, 1, 12, 12, 12, 11, 12, 11, 1, 1, 11, 1, 17, 17, 16, 1, 12, 11, 11, 11, 17, 11, 12, 1, 12, 11, 11, 11, 11, 12, 11, 12, 10, 11, 17, 11, 10, 11, 11, 11, 12, 1, 12, 1, 11, 11, 11, 10, 1, 10, 11, 12, 17, 1, 12, 12, 11, 10, 11, 11, 11, 1, 11, 10, 11, 10, 11, 16, 10, 12, 12, 1, 11, 1, 12, 10, 1, 11, 11, 11, 16, 11, 10, 11, 11, 12, 10, 11, 11, 10, 1, 1, 17, 11, 11, 1, 1, 11, 12, 11, 10, 12, 1, 11, 12, 12, 1, 11, 1, 11, 1, 11, 1, 12, 10, 11, 12, 12, 16, 12, 12, 1, 12, 10, 12, 11, 16, 12, 1, 12, 12, 1, 17, 12, 12, 1, 16, 12, 11, 11, 12, 12, 11, 12, 12, 17, 11, 11, 11, 17, 1, 10, 12, 11, 12, 11, 17, 1, 12, 11, 11, 1, 16, 11, 12, 12, 1, 16, 11, 10, 11, 11, 10, 1, 11, 11, 11, 1, 1, 17, 10, 16, 11, 12, 12, 12, 12, 1, 1, 11, 11, 11, 17, 1, 10, 11, 11, 12, 1, 11, 12, 10, 10, 11, 11, 11, 11, 11, 10, 1, 12, 10, 11, 1, 1, 11, 12, 11, 11, 12, 10, 11, 11, 10, 1, 11, 11, 17, 1, 11, 11, 12, 12, 17, 1, 1, 12, 1, 12, 11, 1, 11, 1, 12, 12, 11, 12, 11, 12, 12, 11, 12, 11, 11, 17, 12, 12, 1, 11, 1, 11, 17, 12, 11, 11, 11, 11, 12, 1, 12, 12, 11, 11, 12, 1, 11, 11, 11, 11, 12, 1, 11, 1, 11, 11, 1, 11, 10, 1, 1, 1, 11, 11, 10, 11, 12, 12, 12, 11, 11, 12, 11, 1, 1, 10, 11, 11, 11, 10, 11, 16, 1, 12, 1, 12, 12, 10, 11, 10, 10, 12, 17, 12, 1, 16, 11, 11, 11, 1, 16, 12, 10, 11, 16, 11, 10, 11, 11, 10, 12, 1, 1, 11, 11, 11, 11, 12, 11, 12, 1, 12, 12, 11, 11, 12, 10, 1, 11, 16, 12, 10, 11, 16, 12, 12, 11, 1, 11, 17, 11, 11, 11, 17, 11, 12, 11, 11, 1, 12, 12, 17, 11, 10, 12, 11, 12, 11, 12, 11, 1, 11, 1, 17, 11, 12, 1, 1, 1, 12, 11, 11, 12, 12, 11, 11, 1, 11, 12, 11, 11, 12, 10, 11, 12, 12, 11, 11, 11, 12, 10, 11, 16, 11, 17, 11, 12, 11, 16, 11, 16, 1, 1, 11, 17, 11, 11, 11, 11, 12, 12, 1, 1, 1, 11, 1, 11, 1, 11, 10, 11, 11, 11, 12, 12, 11, 11, 11, 17, 11, 12, 11, 17, 11, 11, 17, 11, 11, 12, 12, 11, 10, 11, 12, 10, 12, 1, 11, 11, 12, 12, 10, 12, 11, 10, 17, 11, 11, 12, 1, 1, 11, 12, 11, 17, 11, 11, 11, 10, 12, 11, 10, 11, 11, 11, 12, 1, 11, 12, 10, 11, 1, 11, 11, 12, 16, 1, 10, 10, 12, 12, 1, 11, 11, 12, 11, 11, 11, 1, 11, 11, 11, 12, 11, 17, 17, 11, 12, 12, 12, 10, 1, 10, 11, 10, 12, 17, 11, 12, 11, 17, 11, 11, 1, 10, 12, 11, 12, 1, 11, 12, 1, 1, 1, 11, 10, 16, 12, 11, 11, 11, 12, 12, 11, 12, 11, 11, 11, 11, 11, 12, 11, 16, 10, 17, 12, 10, 12, 11, 11, 1, 1, 17, 12, 12, 1, 17, 11, 11, 11, 10, 1, 16, 16, 1, 1, 11, 11, 11, 12, 17, 11, 11, 11, 1, 12, 11, 11, 1, 11, 11, 11, 11, 12, 12, 12, 17, 11, 11, 12, 12, 11, 11, 11, 12, 1, 16, 11, 10, 17, 12, 12, 12, 12, 16, 11, 10, 1, 12, 12, 1, 12, 11, 11, 1, 1, 10, 11, 10, 12, 11, 11, 11, 11, 11, 12, 12, 12, 1, 11, 11, 11, 16, 11, 11, 12, 12, 10, 12, 11, 12, 11, 11, 12, 11, 11, 10, 1, 1, 11, 11, 16, 11, 12, 11, 11, 1, 1, 11, 11, 1, 1, 11, 11, 11, 12, 12, 12, 11, 12, 1, 10, 1, 10, 11, 12, 10, 12, 16, 11, 12, 1, 12, 12, 12, 10, 12, 11, 11, 11, 10, 12, 11, 12, 1, 11, 17, 11, 11, 12, 11, 1, 11, 10, 1, 1, 1, 11, 11, 11, 16, 12, 11, 11, 1, 12, 11, 11, 11, 1, 1, 11, 11, 11, 12, 11, 1, 11, 11, 11, 11, 12, 11, 10, 1, 1, 11, 11, 11, 12, 17, 1, 17, 11, 12, 12, 10, 10, 17, 12, 11, 12, 11, 11, 11, 11, 11, 1, 11, 11, 11, 12, 17, 12, 11, 17, 16, 10, 11, 1, 11, 12, 1, 11, 11, 10, 11, 11, 12, 10, 12, 1, 11, 12, 1, 12, 12, 11, 12, 11, 11, 1, 11, 12, 1, 10, 11, 12, 11, 10, 11, 12, 11, 1, 10, 12, 11, 1, 11, 11, 12, 11, 11, 12, 11, 17, 1, 12, 11, 11, 11, 1, 11, 11, 10, 1, 16, 11, 11, 12, 12, 1, 12, 12, 11, 16, 16, 16, 1, 12, 11, 10, 11, 11, 10, 11, 1, 1, 12, 11, 10, 12, 11, 12, 11, 12, 11, 12, 1, 11, 1, 11, 10, 11, 12, 1, 1, 10, 11, 10, 11, 16, 11, 11, 11, 12, 11, 11, 1, 11, 11, 11, 12, 11, 12, 10, 11, 12, 1, 11, 17, 12, 12, 1, 11, 11, 16, 12, 11, 11, 11, 11, 11, 12, 1, 11, 16, 12, 11, 17, 1, 11, 11, 11, 11, 12, 11, 16, 11, 12, 12, 1, 11, 11, 10, 11, 16, 17, 12, 1, 11, 11, 11, 11, 10, 11, 11, 11, 10, 1, 11, 1, 11, 11, 12, 11, 1, 11, 11, 17, 12, 10, 11, 11, 11, 11, 11, 11, 11, 12, 12, 1, 11, 11, 11, 10, 12, 11, 11, 11, 1, 11, 11, 1, 11, 1, 11, 11, 1, 11, 11, 1, 12, 1, 11, 12, 12, 11, 1, 11, 1, 11, 12, 12, 12, 11, 1, 10, 11, 11, 1, 11, 17, 12, 11, 12, 10, 10, 1, 10, 10, 11, 17, 11, 12, 10, 11, 12, 10, 12, 12, 11, 11, 1, 11, 12, 12, 11, 11, 1, 17, 11, 11, 11, 12, 11, 12, 12, 11, 11, 12, 11, 10, 11, 12, 11, 1, 11, 1, 11, 11, 11, 11, 1, 10, 1, 1, 11, 11, 1, 11, 1, 1, 12, 10, 17, 12, 11, 12, 1, 1, 12, 10, 12, 12, 12, 12, 1, 12, 16, 11, 12, 11, 16, 16, 11, 12, 11, 11, 12, 12, 11, 12, 12, 11, 1, 1, 10, 12, 11, 1, 11, 12, 10, 10, 1, 10, 12, 12, 11, 11, 11, 11, 1, 1, 16, 1, 11, 1, 12, 10, 11, 11, 17, 11, 1, 11, 11, 10, 12, 12, 1, 1, 11, 1, 11, 11, 10, 12, 10, 10, 11, 10, 11, 12, 11, 1, 11, 12, 1, 17, 1, 17, 12, 11, 10, 11, 1, 12, 11, 10, 11, 12, 11, 11, 10, 10, 12, 16, 11, 1, 12, 11, 12, 12, 12, 11, 11, 11, 11, 1, 17, 1, 12, 16, 12, 11, 12, 12, 17, 1, 12, 11, 11, 10, 11, 17, 10, 12, 12, 11, 12, 11, 11, 11, 12, 11, 12, 12, 1, 12, 11, 17, 11, 11, 1, 10, 17, 10, 11, 16, 11, 12, 1, 12, 11, 12, 1, 11, 11, 11, 11, 12, 1, 11, 11, 12, 12, 11, 16, 12, 12, 11, 11, 11, 11, 11, 1, 11, 11, 11, 11, 12, 11, 12, 11, 11, 11, 11, 10, 11, 11, 17, 17, 11, 11, 1, 11, 1, 1, 11, 11, 1, 12, 10, 11, 10, 10, 12, 1, 12, 11, 1, 1, 11, 11, 1, 1, 12, 12, 11, 11, 12, 11, 12, 11, 17, 11, 1, 1, 10, 10, 1, 11, 11, 1, 10, 17, 10, 12, 12, 11, 12, 17, 11, 11, 1, 1, 12, 11, 11, 11, 10, 12, 10, 11, 11, 12, 11, 12, 12, 12, 11, 12, 11, 12, 12, 1, 1, 17, 1, 12, 10, 1, 11, 11, 1, 11, 1, 12, 12, 11, 11, 10, 11, 12, 1, 10, 11, 12, 10, 11, 11, 12, 1, 11, 1, 11, 1, 17, 1, 16, 10, 1, 12, 12, 12, 1, 11, 1, 12, 11, 1, 11, 1, 10, 11, 11, 11, 11, 11, 11, 1, 12, 11, 11, 12, 12, 12, 11, 11, 11, 12, 12, 10, 11, 11, 11, 12, 12, 11, 11, 1, 11, 10, 11, 12, 11, 12, 1, 10, 12, 12, 10, 1, 11, 11, 16, 11, 16, 11, 1, 17, 11, 1, 1, 11, 1, 11, 12, 12, 1, 11, 11, 12, 11, 12, 12, 1, 11, 11, 11, 11, 10, 16, 10, 12, 1, 1, 12, 10, 11, 1, 11, 11, 11, 11, 16, 11, 12, 1, 11, 1, 12, 11, 1, 12, 17, 1, 11, 11, 1, 1, 11, 11, 11, 11, 10, 11, 11, 11, 11, 11, 1, 11, 11, 10, 16, 11, 11, 10, 11, 11, 12, 11, 1, 11, 11, 11, 1, 11, 11, 10, 11, 12, 1, 17, 12, 1, 1, 11, 11, 11, 11, 11, 16, 12, 12, 12, 10, 12, 11, 12, 16, 12, 17, 1, 11, 12, 12, 11, 1, 10, 11, 17, 11, 11, 10, 12, 12, 11, 1, 1, 12, 16, 12, 11, 16, 11, 11, 1, 1, 1, 12, 11, 10, 1, 11, 12, 12, 12, 12, 1, 12, 11, 11, 17, 12, 11, 10, 1, 11, 11, 17, 11, 12, 11, 11, 17, 12, 12, 17, 12, 10, 17, 12, 1, 1, 11, 11, 11, 1, 11, 11, 11, 11, 12, 11, 10, 1, 12, 1, 12, 12, 11, 1, 1, 12, 12, 1, 10, 1, 12, 12, 11, 11, 12, 11, 12, 11, 11, 10, 10, 16, 12, 11, 11, 11, 11, 11, 12, 12, 10, 12, 10, 12, 1, 11, 11, 1, 11, 12, 16, 1, 11, 11, 12, 11, 1, 12, 11, 1, 11, 1, 11, 16, 10, 12, 11, 1, 11, 1, 11, 11, 11, 12, 11, 16, 11, 17, 1, 12, 17, 10, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "prediction = []\n",
    "for i in range(len(test_df)):\n",
    "    prediction = prediction + [classify_example(test_df.iloc[i], tree)]\n",
    "print(prediction)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df, tree):\n",
    "\n",
    "    df[\"classification\"] = df.apply(classify_example, args=(tree,), axis=1)\n",
    "    df[\"classification_correct\"] = df[\"classification\"] == df[\"label\"]\n",
    "    \n",
    "    accuracy = df[\"classification_correct\"].mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994859933179131"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(test_df, tree)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = data[:, -1]#столбец значений\n",
    "unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
